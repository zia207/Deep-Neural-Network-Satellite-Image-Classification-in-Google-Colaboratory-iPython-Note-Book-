{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/Deep-Neural-Network-Satellite-Image-Classification-in-Google-Colaboratory-iPython-Note-Book-/blob/master/data_wrangling_with_dplyr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGoP0AbXEAUx"
      },
      "source": [
        "# Data Wrangling with dplyr and tidyr\n",
        "\n",
        "Zia AHMED, University at Buffalo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the upcoming section, you will delve deeper into data manipulation using two of the most widely used and versatile R-packages: **tidyr** and **dplyr**. Both these packages are part of the **tidyverse**,  a comprehensive suite of R packages specially designed for data science applications. By mastering the functionalities of these two packages, you will be able to seamlessly transform, clean, and manipulate data in a streamlined and efficient manner. The **tidyr** package provides a set of tools to tidy data in a consistent and structured manner. In contrast, the **dplyr** package offers a range of functions to filter, sort, group, and summarize data frames efficiently. With the combined power of these two packages, you will be well-equipped to handle complex data manipulation tasks and derive meaningful insights from your data."
      ],
      "metadata": {
        "id": "LaEnzRvw8N1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **tidyr - Package**\n",
        "\n",
        "[**tidyr**](https://tidyr.tidyverse.org/)  is a powerful data manipulation package that enables users to create **tidy** data, a specific format that makes it easy to work with, model, and visualize data. Tidy data follows a set of principles for organizing data into tables, where each column represents a variable, and each row represents an observation. The variables should have clear, descriptive names that are easy to understand, and the observations should be organized in a logical order. Tidy data is essential because it makes it easier to perform data analysis and visualization. Data in this format can be easily filtered, sorted, and summarized, which is particularly important when working with large datasets. Moreover, it allows users to apply a wide range of data analysis techniques, including regression, clustering, and machine learning, without having to worry about data formatting issues. Tidy data is the preferred format for many data analysis tools and techniques, including the popular R programming language.\n",
        "\n",
        "**tidyr**, package provides a suite of functions for cleaning, reshaping, and transforming data into a tidy format. It allows users to split, combine, and pivot data frames, which are essential operations when working with messy data. Overall, tidyr is a powerful tool that helps users to create tidy data, which is a structured and organized format that makes it easier to analyze and visualize data. Tidy data is a fundamental concept in data science and is widely used in many data analysis tools and techniques.\n"
      ],
      "metadata": {
        "id": "al0deDDV-bkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1s2ve_z1T_bXG4BXNUjyHWkvsg4HJHnMh)\n",
        "\n"
      ],
      "metadata": {
        "id": "k9ZA0ZNw-tw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tidyr** functions fall into five main categories:\n",
        "\n",
        "-   **Pivotting** which converts between long(**pivot_longer()**) and wide forms (**pivot_wider()**), replacing\n",
        "\n",
        "-   **Rectangling**, which turns deeply nested lists (as from JSON) into tidy tibbles.\n",
        "\n",
        "-   **Nesting** converts grouped data to a form where each group becomes a single row containing a nested data frame\n",
        "\n",
        "-   **Splitting and combining character columns**. Use **separate()** and **extract()** to pull a single character column into multiple columns;\n",
        "\n",
        "-   Make implicit missing values explicit with **complete()**; make explicit missing values implicit with **drop_na()**; replace missing values with next/previous value with **fill()**, or a known value with **replace_na()**."
      ],
      "metadata": {
        "id": "FYCjnGeZ-uWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **dplyr - Package**\n",
        "\n",
        "[**dplyr**]( https://dplyr.tidyverse.org/)  provides data manipulation grammar and a set of functions to efficiently clean, process, and aggregate data. It offers a tibble data structure, which is similar to a data frame but designed for easier use and better efficiency. Also, it provides a set of verbs for data manipulation, such as filter(), arrange(), select(), mutate(), and summarize(), to perform various data operations. Additionally, dplyr has a chainable syntax with pipe (%>% or |>), making it easy to execute multiple operations in a single line of code. Finally, it also supports working with remote data sources, including databases and big data systems.\n",
        "\n",
        "On the other hand, tidyr helps to create tidy data that is easy to manipulate, model, and visualize. This type of data follows a set of rules for organizing variables, values, and observations into tables, where each column represents a variable, and each row represents an observation. Tidy data makes it easier to perform data analysis and visualization and is the preferred format for many data analysis tools and techniques."
      ],
      "metadata": {
        "id": "rD7dBhEdDTcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1rzkAr_dhjcJKHgn9ae_4No8_BR7_W3xw)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y4BmY0D_C4z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to data frames/tibbles, dplyr makes working with following packages:\n",
        "\n",
        "[**dtplyr**](https://dtplyr.tidyverse.org/): for large, in-memory datasets. Translates your dplyr code to high performance data.table code.\n",
        "\n",
        "[**dbplyr**](https://dbplyr.tidyverse.org/): for data stored in a relational database. Translates your dplyr code to SQL.\n",
        "\n",
        "[**sparklyr**](https://spark.rstudio.com/): for very large datasets stored in Apache Spark."
      ],
      "metadata": {
        "id": "CSEW2mN0FOXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheat-sheet\n",
        "\n",
        "Here below data Wrangling with [dplyr and tidyr Cheat Sheets](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf):\n",
        "\n",
        "![alt text](http://drive.google.com/uc?export=view&id=1mceCqNLcjsckcXod2BRuJx7pjAB9EBBz)\n",
        "\n"
      ],
      "metadata": {
        "id": "6U9i1T2iFPje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1o04SlxwbZI9v3UJ8kqdb7Pw689fiyqdr)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wi3Tc_LQFyaE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdQJ-mgsEU9J"
      },
      "source": [
        "## Install rpy2\n",
        "\n",
        "Easy way to run R in Colab with Python runtime using **rpy2** python package. We have to install this package using the pip command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOD7NpajDy5k"
      },
      "outputs": [],
      "source": [
        "!pip uninstall rpy2 -y\n",
        "! pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEDD0ccEurf"
      },
      "source": [
        "##  Mount Google Drive\n",
        "\n",
        "Then you must create a folder in Goole drive named \"R\" to install all packages permanently. Before installing R-package in Python runtime. You have to mount Google Drive and follow on-screen instruction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lClKZUW1Eu_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a68538-dc00-4a23-dc58-a94484666772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check and Install Required R Packages"
      ],
      "metadata": {
        "id": "O8mTSRI-GknP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "pkg <- c('tidyverse')\n",
        "new.packages <- pkg[!(pkg %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "JbN1rkO7Gh2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pacakge"
      ],
      "metadata": {
        "id": "DjDmVyITGsDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "library(tidyverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pn9zXgyGsMM",
        "outputId": "3d592c5a-1143-42a8-a1d6-e36dc7fe6c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
            "✔ dplyr     1.1.4     ✔ readr     2.1.4\n",
            "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
            "✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n",
            "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
            "✔ purrr     1.0.2     \n",
            "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "✖ dplyr::filter() masks stats::filter()\n",
            "✖ dplyr::lag()    masks stats::lag()\n",
            "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "In this exercise we will use following CSV files:\n",
        "\n",
        "1.  usa_division.csv: USA division names with IDs\n",
        "\n",
        "2.  usa_state.csv: USA State names with ID and division ID.\n",
        "\n",
        "3.  usa_corn_production.csv:  USA grain crop production by state from 2012-2022\n",
        "\n",
        "4.  gp_soil_data.csv: Soil carbon with co-variate from four states in the Greatplain region in the USA\n",
        "\n",
        "5.  usa_geochemical_raw.csv: Soil geochemical data for the USA, but not cleaned\n",
        "\n",
        "All data set use in this exercise can be downloaded from my [Dropbox](https://www.dropbox.com/scl/fo/fohioij7h503duitpl040/h?rlkey=3voumajiklwhgqw75fe8kby3o&dl=0) or from my [Github](https://github.com/zia207/r-colab/tree/main/Data/R_Beginners) accounts.\n",
        "\n"
      ],
      "metadata": {
        "id": "pcn48RSJ2Xnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `read_csv()` function of **readr** package to import data from github as a **tidy** data."
      ],
      "metadata": {
        "id": "WuwRh_91IxVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "div<-read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_division.csv\")\n",
        "state<-read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_state.csv\")\n",
        "corn<-read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_corn_production.csv\")\n",
        "soil<-read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/gp_soil_data.csv\")\n",
        "head(soil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKhJzcrC0lGY",
        "outputId": "163afd8a-cd27-4499-f96d-8e5712507096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 9 Columns: 2\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr (1): DIVISION_NAME\n",
            "dbl (1): DIVISION_ID\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "Rows: 48 Columns: 3\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr (1): STATE_NAME\n",
            "dbl (2): STATE_ID, DIVISION_ID\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "Rows: 465 Columns: 3\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "dbl (3): STATE_ID, YEAR, MT\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "Rows: 467 Columns: 19\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr  (4): STATE, COUNTY, NLCD, FRG\n",
            "dbl (15): ID, FIPS, STATE_ID, Longitude, Latitude, SOC, DEM, Aspect, Slope, ...\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "# A tibble: 6 × 19\n",
            "     ID  FIPS STATE_ID STATE  COUNTY Longitude Latitude   SOC   DEM Aspect Slope\n",
            "  <dbl> <dbl>    <dbl> <chr>  <chr>      <dbl>    <dbl> <dbl> <dbl>  <dbl> <dbl>\n",
            "1     1 56041       56 Wyomi… Uinta…     -111.     41.1  15.8 2229.   159.  5.67\n",
            "2     2 56023       56 Wyomi… Linco…     -111.     42.9  15.9 1889.   157.  8.91\n",
            "3     3 56039       56 Wyomi… Teton…     -111.     44.5  18.1 2423.   169.  4.77\n",
            "4     4 56039       56 Wyomi… Teton…     -111.     44.4  10.7 2484.   198.  7.12\n",
            "5     5 56029       56 Wyomi… Park …     -111.     44.8  10.5 2396.   201.  7.95\n",
            "6     6 56039       56 Wyomi… Teton…     -111.     44.1  17.0 2361.   209.  9.66\n",
            "# ℹ 8 more variables: TPI <dbl>, KFactor <dbl>, MAP <dbl>, MAT <dbl>,\n",
            "#   NDVI <dbl>, SiltClay <dbl>, NLCD <chr>, FRG <chr>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipe Operator\n",
        "\n",
        "At the beginning of this tutorial, I would like to provide you with a comprehensive overview of the Pipe Operator. This operator is a crucial tool for data wrangling in R. It is denoted by the symbols `%>%` or `| >`  (keyboard shortcut **shift+ctrl M**) and requires the use of **R 4.1 or higher**.\n",
        "\n",
        "The Pipe Operator has been an integral part of the **magrittr** package for R for some time now. It allows us to take the output of one function and use it as an argument in another function, which helps us chain together a sequence of analysis steps.\n",
        "\n",
        "To put it simply, suppose we have two functions, A and B. The output of function A can be passed directly to function B using the Pipe Operator. This way, we can avoid the need to store the intermediate results in variables, which can make our code more concise and easier to read.\n",
        "\n",
        "In this tutorial, we will provide an example of how to use the Pipe Operator in a real-world scenario. We will demonstrate how it can help us to perform a sequence of data manipulation steps efficiently. So, stay tuned to learn more about this essential operator, and how you can use it to improve your data analysis skills in R."
      ],
      "metadata": {
        "id": "8FyowqdjJ2Xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Important Functions\n",
        "\n"
      ],
      "metadata": {
        "id": "TUVQPkZtLMb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Join\n",
        "\n",
        "In R programming language, there are several functions to merge two dataframes. The `base::merge()` function is one such function that can be used to merge dataframes. This function is available in the `join()` function of the dplyr package. The `base::merge()` function can merge two dataframes based on one or more common columns.\n",
        "\n",
        "Before merging two dataframes, it's important to ensure that the dataframes have a common column (or columns) to merge on. These columns are called \"key\" variables. The most important condition for joining two dataframes is that the column type of \"key\" variables should be the same in both dataframes. If the column types are different, the merge operation might result in unexpected errors.\n",
        "\n",
        "In R, there are different types of `base::merge()` functions available for different types of merges such as left, right, inner, and outer. Additionally, the dplyr package provides several `join()` functions like `inner_join()`, `left_join()`, `right_join()`, and `full_join()`. These functions can be used to merge dataframes based on different conditions. For example, `inner_join()` returns only the rows that have matching values in both dataframes, `left_join()` returns all rows from the left dataframe and the matching rows from the right dataframe, and so on.\n",
        "\n",
        "Types of `base::merge()` and several `join()` function of dplyr available in R are:"
      ],
      "metadata": {
        "id": "mT6E6_ijd8yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1ArfIZBYWSpvnr5fYP9eJf6e-FurFbkSV)\n",
        "\n"
      ],
      "metadata": {
        "id": "qNmu-9XCNjxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`inner_join()` is a function in the **dplyr** library that performs an inner join on two data frames. An inner join returns only the rows that have matching values in both data frames. If there is no match in one of the data frames for a row in the other data frame, the result will not contain that row.\n",
        "\n",
        "> inner_join(x, y, .....)\n",
        "\n",
        "We will join state, division and USA corn production data one by one e using `inner_join()` function:"
      ],
      "metadata": {
        "id": "7V_B1ZN_N76x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn_state = dplyr::inner_join(corn, state)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ7YEMR2J2wO",
        "outputId": "1c1b543e-020b-49e7-cda7-6f0defb88ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joining with `by = join_by(STATE_ID)`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn_state_div = dplyr::inner_join(corn_state, div)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKa9GOAGOHcQ",
        "outputId": "6e0afc5e-1bad-4cda-d474-1a50749a8d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joining with `by = join_by(DIVISION_ID)`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run multiple `inner_join()` functions in a series with pipe `%>%` or `|>` operator:"
      ],
      "metadata": {
        "id": "y-G3MprPO1o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.usa = dplyr::inner_join(corn, state)  |>\n",
        "     dplyr::inner_join(div)  |>\n",
        "  glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "935NyNNYO2pN",
        "outputId": "41d02b3e-fd3f-4afa-e294-8f8dff5c8dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joining with `by = join_by(STATE_ID)`\n",
            "Joining with `by = join_by(DIVISION_ID)`\n",
            "Rows: 465\n",
            "Columns: 6\n",
            "$ STATE_ID      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 9968…\n",
            "$ STATE_NAME    <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"…\n",
            "$ DIVISION_ID   <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ DIVISION_NAME <chr> \"East South Central\", \"East South Central\", \"East South …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`glimpse()` function is similar to the `print()` function, but with one significant difference. In `glimpse()`, columns are displayed vertically, and data is displayed horizontally. This makes it easier to view all the columns in a data frame. It is similar to the `str()` function, but it shows more data. Additionally, it always displays the underlying data, even when used with a remote data source."
      ],
      "metadata": {
        "id": "QxcAcJgmPL_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relocate\n",
        "\n",
        "The `relocate()` function can be used to rearrange the positions of columns in a tabular dataset. This function works in a similar way to the `select()` function, making it easy to move blocks of columns at once. By using the `relocate()` function, you can specify the new positions of columns in the dataset and ensure that they are in the desired order. This can be particularly useful when working with large datasets that require reorganization of columns to suit specific needs.\n",
        "\n",
        "Now we will organize DIVISION_FIPS, DIVISION_NAME, STATE_FIPS, STATE_NAME, DIVISION_NAME, YEAR, MT with `relocate()` function:\n",
        "\n",
        "\n",
        "> relocate(.data, ..., .before = NULL, .after = NULL)"
      ],
      "metadata": {
        "id": "FWX9PhEuRy9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.usa = dplyr::inner_join(corn, state)  |>\n",
        "         dplyr::inner_join(div)  |>\n",
        "         glimpse()\n",
        "head(mf.usa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZj-VPQURzfz",
        "outputId": "1042b773-0bb2-42d3-fb21-5b8062fddfd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joining with `by = join_by(STATE_ID)`\n",
            "Joining with `by = join_by(DIVISION_ID)`\n",
            "Rows: 465\n",
            "Columns: 6\n",
            "$ STATE_ID      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 9968…\n",
            "$ STATE_NAME    <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"…\n",
            "$ DIVISION_ID   <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ DIVISION_NAME <chr> \"East South Central\", \"East South Central\", \"East South …\n",
            "# A tibble: 6 × 6\n",
            "  STATE_ID  YEAR       MT STATE_NAME DIVISION_ID DIVISION_NAME     \n",
            "     <dbl> <dbl>    <dbl> <chr>            <dbl> <chr>             \n",
            "1        1  2012  734353. Alabama              2 East South Central\n",
            "2        1  2013 1101529. Alabama              2 East South Central\n",
            "3        1  2014 1151062. Alabama              2 East South Central\n",
            "4        1  2015  914829. Alabama              2 East South Central\n",
            "5        1  2016  960171. Alabama              2 East South Central\n",
            "6        1  2017  996876. Alabama              2 East South Central\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOk85Ol6GQfH"
      },
      "source": [
        "### Rename\n",
        "\n",
        "The `rename()` function can be used to change the name of an individual variable. The syntax for this is new_name = old_name. On the other hand, the `rename_with()` function can be used to rename columns in a dataframe. This function accepts a function that is used to generate new names for the columns. The function should take a string as input and return a string as output. The `rename_with()` function is a powerful tool that allows you to rename columns based on specific criteria or patterns. With this function, you can easily rename columns in a dataframe without having to manually change each column name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXfSYaGPGpbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a670370-da00-453c-a0b6-2ae174dffc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"STATE_FIPS\"    \"YEAR\"          \"MT\"            \"STATE_NAME\"   \n",
            "[5] \"DIVISION_ID\"   \"DIVISION_NAME\"\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "df.usa <- mf.usa  |>\n",
        "          dplyr::rename(\"STATE_FIPS\" = \"STATE_ID\")\n",
        "names(df.usa)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipe Join, Relocate and Rename functions\n",
        "\n",
        "We can run `inner_join()`, `relocate()`, and `rename()` in a single line with pipe:"
      ],
      "metadata": {
        "id": "aVKbOwceUgks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.corn = dplyr::inner_join(corn, state) |>\n",
        "          dplyr::inner_join(div)  |>\n",
        "          dplyr::relocate(DIVISION_ID,\n",
        "                          DIVISION_NAME,\n",
        "                          STATE_ID,\n",
        "                          STATE_NAME,\n",
        "                          YEAR,\n",
        "                          MT,\n",
        "                         .after =  DIVISION_ID) |>\n",
        "          dplyr::rename(\"STATE_FIPS\" = \"STATE_ID\")  |>\n",
        "        glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFOKam9niuon",
        "outputId": "1fd49d61-522d-48a1-e26c-22a540eba53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joining with `by = join_by(STATE_ID)`\n",
            "Joining with `by = join_by(DIVISION_ID)`\n",
            "Rows: 465\n",
            "Columns: 6\n",
            "$ DIVISION_ID   <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ DIVISION_NAME <chr> \"East South Central\", \"East South Central\", \"East South …\n",
            "$ STATE_FIPS    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ STATE_NAME    <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 9968…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select\n",
        "\n",
        "The `dplyr::select()` function is a powerful and versatile tool used to extract a subset of columns from a data frame in R programming. This function enables you to select specific columns based on their name or position within the data frame. By using the **dplyr** package, you can perform common data manipulation tasks efficiently and effectively. This package provides a set of functions that are designed to work seamlessly with one another to streamline the data manipulation process.\n",
        "\n",
        "***Overview of selection features***\n",
        "\n",
        "```\n",
        "Tidyverse selections implement a dialect of R where operators make it easy to select variables:\n",
        "```\n",
        "\n",
        "-   `:`for selecting a range of consecutive variables.\n",
        "\n",
        "-   `!`for taking the complement of a set of variables.\n",
        "\n",
        "-   `&`and  `|`for selecting the intersection or the union of two sets of variables.\n",
        "\n",
        "-   `c()` for combining selections.\n",
        "\n",
        "```  \n",
        "In addition, you can use **selection helpers**. Some helpers select specific columns:\n",
        "```  \n",
        "-   [`everything()`](http://127.0.0.1:9029/help/library/tidyselect/help/everything): Matches all variables.\n",
        "\n",
        "-   [`last_col()`](http://127.0.0.1:9029/help/library/tidyselect/help/everything): Select last variable, possibly with an offset.\n",
        "\n",
        "-   [`group_cols()`](http://127.0.0.1:9029/help/library/dplyr/help/group_cols): Select all grouping columns.\n",
        "\n",
        "```  \n",
        "Other helpers select variables by matching patterns in their names:\n",
        "```  \n",
        "\n",
        "-   [`starts_with()`](http://127.0.0.1:9029/help/library/tidyselect/help/starts_with): Starts with a prefix.\n",
        "\n",
        "-   [`ends_with()`](http://127.0.0.1:9029/help/library/tidyselect/help/starts_with): Ends with a suffix.\n",
        "\n",
        "-   [`contains()`](http://127.0.0.1:9029/help/library/tidyselect/help/starts_with): Contains a literal string.\n",
        "\n",
        "-   [`matches()`](http://127.0.0.1:9029/help/library/tidyselect/help/starts_with): Matches a regular expression.\n",
        "\n",
        "-   [`num_range()`](http://127.0.0.1:9029/help/library/tidyselect/help/starts_with): Matches a numerical range like x01, x02, x03.\n",
        "\n",
        "```         \n",
        "Or from variables stored in a character vector:\n",
        "```\n",
        "-   [`all_of()`](http://127.0.0.1:9029/help/library/tidyselect/help/all_of): Matches variable names in a character vector. All names must be present, otherwise an out-of-bounds error is thrown.\n",
        "\n",
        "-   [`any_of()`](http://127.0.0.1:9029/help/library/tidyselect/help/all_of): Same as all_of(), except that o error is thrown for names that don't\n",
        "\n",
        "```         \n",
        "Or using a predicate function:\n",
        "```\n",
        "-   [`where()`](http://127.0.0.1:9029/help/library/tidyselect/help/where): Applies a function to all variables and selects those for which the function returns TRUE.\n",
        "\n",
        "Now we will use `select()` to create a dataframe with state names, year and production:"
      ],
      "metadata": {
        "id": "M-Q9xWCLit23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `select()` to create a dataframe with state names, year and production"
      ],
      "metadata": {
        "id": "dY5A0e8Wx7oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.state <- df.corn |>\n",
        "            dplyr::select(STATE_NAME,\n",
        "                          YEAR,\n",
        "                          MT) |>\n",
        "            glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBXiV8FK9zHJ",
        "outputId": "577f5b76-469a-4c86-9f97-c4c7cce914dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465\n",
            "Columns: 3\n",
            "$ STATE_NAME <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Ala…\n",
            "$ YEAR       <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021,…\n",
            "$ MT         <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 996875.…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter\n",
        "\n",
        "The `filter()` function in R is a powerful tool for working with data frames. It allows you to subset a data frame by retaining only the rows that meet specific conditions.\n",
        "\n",
        "When using `filter()`, you must provide one or more conditions that each row must satisfy. For example, you may want to filter a data frame to only include rows where a certain column meets a certain condition, such as all rows where the value of a column is greater than 10.\n",
        "\n",
        "To specify conditions, you can use logical operators such as `==`, `!=`, `<`, `>`, `<=`, and `>=`. You can also use the `%in%` operator to check if a value is contained in a list.\n",
        "\n",
        "It's important to note that when using `filter()`, each row must satisfy all the given conditions to be retained. If a condition evaluates to `FALSE` or `NA`, that row will be dropped from the resulting data frame.\n",
        "\n",
        "Unlike base subsetting with `[`, if a condition evaluates to `NA`, the row will also be dropped. This is because R treats `NA` as an undefined value, and so it can't determine whether the condition is satisfied or not.\n",
        "\n",
        "Overall, `filter()` is a useful function for working with data frames in R, and its ability to subset data based on specific conditions can be very helpful when working with large data sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "1jX5VaKM0MMV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lm8_XGaG8Il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e21f1e8-58d4-4f7e-ff73-174f13313413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Illinois\"  \"Indiana\"   \"Michigan\"  \"Ohio\"      \"Wisconsin\"\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "df.01<-df.corn |>\n",
        "       dplyr::filter(DIVISION_NAME == \"East North Central\")\n",
        "levels(as.factor(df.01$STATE_NAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering by multiple criteria within a single logical expression - select data from East North Central, South Central and Middle Atlantic Division"
      ],
      "metadata": {
        "id": "d35_rXRfjFxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.02<- df.corn  |>\n",
        "        dplyr::filter(DIVISION_NAME %in%c(\"East North Central\",\n",
        "                                          \"East South Central\",\n",
        "                                          \"Middle Atlantic\"))\n",
        "levels(as.factor(df.02$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6LcSJkfytdz",
        "outputId": "753c1e77-ea12-4667-97aa-6355c9770759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1] \"Alabama\"      \"Illinois\"     \"Indiana\"      \"Kentucky\"     \"Michigan\"    \n",
            " [6] \"Mississippi\"  \"New Jersey\"   \"New York\"     \"Ohio\"         \"Pennsylvania\"\n",
            "[11] \"Tennessee\"    \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or we can use `|` which represents `OR` in the logical condition, any of the two conditions. based on the sample data.."
      ],
      "metadata": {
        "id": "SqJQoPMbC4sA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.03<- df.usa |>\n",
        "        dplyr::filter(DIVISION_NAME == \"East North Central\" | DIVISION_NAME == \"Middle Atlantic\")\n",
        "levels(as.factor(df.03$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK9Hjeb0zLcH",
        "outputId": "c1edf383-d44f-4b22-9f31-fb0126bc0b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Illinois\"     \"Indiana\"      \"Michigan\"     \"New Jersey\"   \"New York\"    \n",
            "[6] \"Ohio\"         \"Pennsylvania\" \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following filter create a files for the Middle Atlantic Division only with New York state."
      ],
      "metadata": {
        "id": "yW9YgYly0LXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.ny<-df.corn  |>\n",
        "         dplyr::filter(DIVISION_NAME == \"Middle Atlantic\" & STATE_NAME == \"New York\")\n",
        "head(df.ny)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OOhwWP40Loc",
        "outputId": "94529096-fd33-4320-b95d-8dc7b28f43d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 6 × 6\n",
            "  DIVISION_ID DIVISION_NAME   STATE_FIPS STATE_NAME  YEAR       MT\n",
            "        <dbl> <chr>                <dbl> <chr>      <dbl>    <dbl>\n",
            "1           3 Middle Atlantic         36 New York    2012 2314570.\n",
            "2           3 Middle Atlantic         36 New York    2013 2401189.\n",
            "3           3 Middle Atlantic         36 New York    2014 2556391 \n",
            "4           3 Middle Atlantic         36 New York    2015 2143111.\n",
            "5           3 Middle Atlantic         36 New York    2016 1867761.\n",
            "6           3 Middle Atlantic         36 New York    2017 1983464.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following filters will select State where corn production (MT) is greater than the global average of production"
      ],
      "metadata": {
        "id": "nfFxl4_t0Tzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mean.prod <- df.corn |>\n",
        "              dplyr::filter(MT > mean(MT, na.rm = TRUE))\n",
        "levels(as.factor(mean.prod$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvEB5Hfj0UcJ",
        "outputId": "93b29eaf-9205-45d0-b8c7-efefae0ea6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1] \"Illinois\"     \"Indiana\"      \"Iowa\"         \"Kansas\"       \"Michigan\"    \n",
            " [6] \"Minnesota\"    \"Missouri\"     \"Nebraska\"     \"North Dakota\" \"Ohio\"        \n",
            "[11] \"South Dakota\" \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use will `&` in the following filters to select states or rows where `MT` is greater than the global average of for the year 2017"
      ],
      "metadata": {
        "id": "O1hHSzbp0dns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mean.prod.2017 <- df.corn |>\n",
        "              dplyr::filter(MT > mean(MT, na.rm = TRUE) & YEAR ==2017)\n",
        "levels(as.factor(mean.prod.2017$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee_erSje0ek_",
        "outputId": "f082c420-8aec-4a82-b7d3-2eae87a4f73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1] \"Illinois\"     \"Indiana\"      \"Iowa\"         \"Kansas\"       \"Minnesota\"   \n",
            " [6] \"Missouri\"     \"Nebraska\"     \"North Dakota\" \"Ohio\"         \"South Dakota\"\n",
            "[11] \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following command will select counties starting with \"A\". filter() with **grepl()** is used to search for pattern matching."
      ],
      "metadata": {
        "id": "s9GrOCBW0kBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "state.a <- df.corn  |>\n",
        "          dplyr::filter(grepl(\"^A\", STATE_NAME))\n",
        "levels(as.factor(state.a $STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmoaywlx0kIq",
        "outputId": "2e282739-aac1-4120-d6f5-ace82841b2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Alabama\"  \"Arizona\"  \"Arkansas\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarize\n",
        "\n",
        "In the dplyr package, there is a very useful function called `summarize()`. Its purpose is to condense multiple values in a data frame into a single summary value. Essentially, it takes a data frame as input and returns a smaller data frame that contains various summary statistics. For instance, you can use summarize to calculate the mean, sum, count, or any other statistical measure you need to analyze your data. This function is often used in conjunction with other dplyr functions, such as filter and mutate, to manipulate and analyze data effectively. Overall, summarize is a powerful tool that can help you streamline your data analysis tasks and quickly extract valuable insights from your data.\n",
        "\n",
        "-   **Center**: `mean()`, `median()`\n",
        "\n",
        "-   **Spread**: `sd()`, `IQR()`, `mad()`\n",
        "\n",
        "-   **Range**: `min()`, `max()`, `quantile()`\n",
        "\n",
        "-   **Position**: `first()`, `last()`, `nth()`,\n",
        "\n",
        "-   **Count**: `n()`, `n_distinct()`\n",
        "\n",
        "-   **Logical**: `any()`, `all()`\n",
        "\n",
        "`summarise()` and `summarize()` are synonyms."
      ],
      "metadata": {
        "id": "XugoFtb7jy5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKU4UEAtHTHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64186ca6-e940-4dfc-a5e7-f49868b37d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 1\n",
            "    Median\n",
            "     <dbl>\n",
            "1 2072749.\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# mean\n",
        "summarize(df.corn, Mean=mean(MT))\n",
        "# median\n",
        "summarise(df.corn, Median=median(MT))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scoped variants (`_if`, `_at`, `_all`) of `summarise()` make it easy to apply the same transformation to multiple variables. There are three variants.\n",
        "\n",
        "-   `summarise_at()` affects variables selected with a character vector or vars()\n",
        "\n",
        "-   `summarise_all()` affects every variable\n",
        "\n",
        "-   `summarise_if()` affects variables selected with a predicate function\n",
        "\n",
        "Following `summarise_at()`function mean of SOC from USA soil data (soil)."
      ],
      "metadata": {
        "id": "PA_POhKSj_ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil  |>\n",
        "    dplyr::summarise_at(\"SOC\", mean, na.rm = TRUE)"
      ],
      "metadata": {
        "id": "d7aVcx1wkxXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cd893b-edb3-4c01-fbbd-1543e6ac2f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 1\n",
            "    SOC\n",
            "  <dbl>\n",
            "1  6.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiple variables:"
      ],
      "metadata": {
        "id": "ifAPPmS81l4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil  |>\n",
        "    dplyr::summarise_at(c(\"SOC\", \"NDVI\"), mean, na.rm = TRUE)"
      ],
      "metadata": {
        "id": "uBiwbThVlOE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5275a9-80a6-4117-bbbb-14355ce79711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 2\n",
            "    SOC  NDVI\n",
            "  <dbl> <dbl>\n",
            "1  6.35 0.437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `summarise_if()` variants apply a predicate function (a function that returns `TRUE` or `FALSE`) to determine the relevant subset of columns.\n",
        "\n",
        "Here we apply `mean()` to the numeric columns:"
      ],
      "metadata": {
        "id": "qb5WLTYV1yS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil  |>\n",
        "    dplyr::summarise_if(is.numeric, mean, na.rm = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RimFV-HylSYe",
        "outputId": "da424d5e-5dc8-4f7a-a43e-fa1085b31945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 15\n",
            "     ID   FIPS STATE_ID Longitude Latitude   SOC   DEM Aspect Slope     TPI\n",
            "  <dbl>  <dbl>    <dbl>     <dbl>    <dbl> <dbl> <dbl>  <dbl> <dbl>   <dbl>\n",
            "1  238. 29151.     29.1     -104.     38.9  6.35 1632.   165.  4.84 0.00937\n",
            "# ℹ 5 more variables: KFactor <dbl>, MAP <dbl>, MAT <dbl>, NDVI <dbl>,\n",
            "#   SiltClay <dbl>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil  |>\n",
        "   dplyr::summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyd_xIRd16PY",
        "outputId": "5b07dd13-b055-4822-d223-795211b5624c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 15\n",
            "     ID   FIPS STATE_ID Longitude Latitude   SOC   DEM Aspect Slope     TPI\n",
            "  <dbl>  <dbl>    <dbl>     <dbl>    <dbl> <dbl> <dbl>  <dbl> <dbl>   <dbl>\n",
            "1  238. 29151.     29.1     -104.     38.9  6.35 1632.   165.  4.84 0.00937\n",
            "# ℹ 5 more variables: KFactor <dbl>, MAP <dbl>, MAT <dbl>, NDVI <dbl>,\n",
            "#   SiltClay <dbl>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is better to select first our target numerical columns and then apply `summarise_all()`:"
      ],
      "metadata": {
        "id": "mO7r7bfG2Fes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil  |>\n",
        "    # First select  numerical columns\n",
        "    dplyr::select(SOC, DEM, NDVI, MAP, MAT) |>\n",
        "    # get mean of all these variables\n",
        "    dplyr::summarise_all(mean, na.rm = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "150ABc5I2GUi",
        "outputId": "f40deb9c-f7a8-4d16-96c8-a6de1d53a34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 5\n",
            "    SOC   DEM  NDVI   MAP   MAT\n",
            "  <dbl> <dbl> <dbl> <dbl> <dbl>\n",
            "1  6.35 1632. 0.437  501.  8.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutate\n",
        "\n",
        "The `mutate()` function is a powerful tool that can be used to create new columns in a data frame by using expressions that manipulate the values of existing columns or variables. It is a part of the **dplyr** package in R and is used extensively in data manipulation tasks.\n",
        "\n",
        "When you use the `mutate()` function, you can specify new column names and the expressions that will be used to generate the column values. The expressions can use the values from one or more existing columns or variables, and can include arithmetic operations, logical operators, and other functions.\n",
        "\n",
        "The `mutate()` function returns a new data frame with the added columns and the same number of rows as the original dataframe. This means that the original data frame is not modified, and the new data frame can be used for further analysis or visualization tasks.\n",
        "\n",
        "Overall, the `mutate()` function is a versatile tool that can simplify complex data manipulation tasks and streamline your data analysis workflow.\n",
        "\n",
        "In this exercise we will create a new column (MT_1000) in df.corn dataframe dividing MT column by 1000\n",
        "\n"
      ],
      "metadata": {
        "id": "LoHVxqxLz9UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we will create a new column (MT_1000) in df.corn dataframe dividing MT column by 1000"
      ],
      "metadata": {
        "id": "AHdP2wLs3jWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.corn  |>\n",
        "    # get mean of all these variables\n",
        "    dplyr::mutate(MT_1000 = MT / 10000)  |>\n",
        "    glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh615aRi0Ev4",
        "outputId": "333e6f78-c456-4573-f41c-355b1c63ff0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465\n",
            "Columns: 7\n",
            "$ DIVISION_ID   <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ DIVISION_NAME <chr> \"East South Central\", \"East South Central\", \"East South …\n",
            "$ STATE_FIPS    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4,…\n",
            "$ STATE_NAME    <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 9968…\n",
            "$ MT_1000       <dbl> 73.43528, 110.15292, 115.10618, 91.48293, 96.01707, 99.6…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group by\n",
        "\n",
        "The function `group_by()` is used to group a data frame by one or more variables. Once the data is grouped, you can perform various operations on it, such as aggregating with `summarize()`, transforming with `mutate()`, or filtering with `filter()`. The output of grouping is a grouped tibble, which is a data structure that retains the grouping structure and allows you to perform further operations on the grouped data.\n",
        "\n",
        "We can calculate global mean of USA corn production by division:"
      ],
      "metadata": {
        "id": "DQMVgQZwoWkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.corn |>\n",
        "          dplyr::group_by(DIVISION_NAME) |>\n",
        "          dplyr::summarize(Prod_MT = mean(MT))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuwezKCcoZZn",
        "outputId": "e3c2b16c-2a35-4a03-f391-9462c62c8e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 9 × 2\n",
            "  DIVISION_NAME        Prod_MT\n",
            "  <chr>                  <dbl>\n",
            "1 East North Central 22246702.\n",
            "2 East South Central  3143670.\n",
            "3 Middle Atlantic     2036263.\n",
            "4 Mountain             712629.\n",
            "5 New England           15203.\n",
            "6 Pacific              384083.\n",
            "7 South Atlantic      1163065.\n",
            "8 West North Central 27893388.\n",
            "9 West South Central  3163740.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also apply the `group_by()`, `summarize()` and `mutate()` functions with pipe to calculate mean of corn production in 1000 MT by division for the year 2022"
      ],
      "metadata": {
        "id": "Z3lvK9LO4f_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.corn |>\n",
        "          dplyr::filter(YEAR==2020) |>\n",
        "          dplyr::group_by(DIVISION_NAME) |>\n",
        "          dplyr::summarize(Prod_MT = mean(MT)) |>\n",
        "          dplyr::mutate(Prod_1000_MT = Prod_MT / 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAqHRPj0ofr6",
        "outputId": "de318bef-f411-4a3b-b347-e7ae862d5234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 8 × 3\n",
            "  DIVISION_NAME        Prod_MT Prod_1000_MT\n",
            "  <chr>                  <dbl>        <dbl>\n",
            "1 East North Central 22746952.       22747.\n",
            "2 East South Central  3350119.        3350.\n",
            "3 Middle Atlantic     1929554.        1930.\n",
            "4 Mountain             651221.         651.\n",
            "5 Pacific              391731.         392.\n",
            "6 South Atlantic      1223075.        1223.\n",
            "7 West North Central 28281091.       28281.\n",
            "8 West South Central  3009964.        3010.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also apply the `group_by()` and `summarize()` functions to calculate statistic of multiple variable:"
      ],
      "metadata": {
        "id": "l1vfNT2E3YY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil |>\n",
        "  group_by(STATE) |>\n",
        "  summarize(SOC = mean(SOC),\n",
        "            NDVI = mean(NDVI),\n",
        "            MAP = mean(MAP),\n",
        "            MAT = mean(MAT))"
      ],
      "metadata": {
        "id": "1e7cYHTK5LO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a9d0eb-8047-4147-cd1d-7ccbce4baaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 4 × 5\n",
            "  STATE        SOC  NDVI   MAP   MAT\n",
            "  <chr>      <dbl> <dbl> <dbl> <dbl>\n",
            "1 Colorado    7.29 0.482  473.  6.93\n",
            "2 Kansas      7.43 0.570  742. 12.6 \n",
            "3 New Mexico  3.51 0.301  388. 11.6 \n",
            "4 Wyoming     6.90 0.390  419.  5.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code will identify the states where corn production data has not reported for the all years."
      ],
      "metadata": {
        "id": "9NwlDlhu5Csi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.corn |>\n",
        "  dplyr::group_by(STATE_NAME) |>\n",
        "  dplyr::summarise(n = n()) |>\n",
        "  dplyr::filter(n < 11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAGtr1jpoxV-",
        "outputId": "8da11c10-c8c1-4e9c-f095-a3e7264e5375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 7 × 2\n",
            "  STATE_NAME        n\n",
            "  <chr>         <int>\n",
            "1 Connecticut       2\n",
            "2 Maine             2\n",
            "3 Massachusetts     2\n",
            "4 Nevada            2\n",
            "5 New Hampshire     2\n",
            "6 Rhode Island      2\n",
            "7 Vermont           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pivoting Data-frame\n",
        "\n",
        "Pivoting a DataFrame is a data manipulation technique that involves reorganizing the structure of the data to create a new view. This technique is particularly useful when working with large datasets because it can help to make the data more manageable and easier to analyze. In R, pivoting a DataFrame typically involves using the dplyr or tidyr packages to transform the data from a long format to a wide format or vice versa. This allows for easier analysis of the data and can help to highlight patterns, trends, and relationships that might otherwise be difficult to see. Overall, pivoting a DataFrame is an important tool in the data analyst's toolkit and can be used to gain valuable insights into complex datasets.\n",
        "\n",
        "In R, there are multiple ways to pivot a data frame, but the most common methods are:\n",
        "\n",
        "`tidyr::pivot_wider`: The pivot_wider() function is used to reshape a data frame from a long format to a wide format, in which each row becomes a variable, and each column is an observation.\n",
        "\n",
        "`tidyr::pivot_longer`: This is a relatively new function in the tidyr library that makes it easy to pivot a data frame from wide to long format. It is used to reshape a data frame from a wide format to a long format, in which each column becomes a variable, and each row is an observation.\n",
        "\n",
        "`tidyr::spread()`: This function is also used to pivot data from long to wide format. It creates new columns from the values of one column, based on the values of another column.\n",
        "\n",
        "`tidy::gather()` : This function is used to pivot data from wide to long format. It collects values of multiple columns into a single column, based on the values of another column."
      ],
      "metadata": {
        "id": "iHCT14aE5nmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pivot_wider\n",
        "\n",
        "`pivot_wider()` convert a dataset wider by increasing the number of columns and decreasing the number of rows."
      ],
      "metadata": {
        "id": "rMasbZzkG4k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.wider = df.corn  |>\n",
        "           dplyr::select (STATE_FIPS,STATE_NAME, YEAR, MT) |>\n",
        "           # Drop state where reporting years less than 11\n",
        "           dplyr::filter(STATE_NAME!= 'Connecticut',\n",
        "                        STATE_NAME!= 'Maine',\n",
        "                        STATE_NAME!= 'Massachusetts',\n",
        "                        STATE_NAME!= 'Nevada',\n",
        "                        STATE_NAME!= 'New Hampshire',\n",
        "                        STATE_NAME!= 'Rhode Island',\n",
        "                        STATE_NAME!= 'Vermont') %>%\n",
        "           tidyr::pivot_wider(names_from = YEAR, values_from = MT)\n",
        "head(corn.wider)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjFh0Wg-5nZg",
        "outputId": "c97a2a1f-c34f-4057-8f9f-bc9441716209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 6 × 13\n",
            "  STATE_FIPS STATE_NAME  `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019`\n",
            "       <dbl> <chr>        <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n",
            "1          1 Alabama     7.34e5 1.10e6 1.15e6 9.15e5 9.60e5 9.97e5 9.71e5 1.14e6\n",
            "2          4 Arizona     1.59e5 2.29e5 1.49e5 1.92e5 2.73e5 1.59e5 1.12e5 2.17e5\n",
            "3          5 Arkansas    3.14e6 4.11e6 2.52e6 2.05e6 3.24e6 2.77e6 2.97e6 3.27e6\n",
            "4          6 California  8.23e5 8.73e5 3.98e5 2.39e5 4.70e5 3.39e5 2.86e5 2.56e5\n",
            "5          8 Colorado    3.41e6 3.26e6 3.75e6 3.43e6 4.07e6 4.72e6 3.93e6 4.06e6\n",
            "6         10 Delaware    6.10e5 7.34e5 8.53e5 8.00e5 7.08e5 8.21e5 6.11e5 7.36e5\n",
            "# ℹ 3 more variables: `2020` <dbl>, `2021` <dbl>, `2022` <dbl>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pivot_longer\n",
        "\n",
        "The `pivot_longer()` function can be used to pivot a data frame from a wide format to a long format."
      ],
      "metadata": {
        "id": "UWh5fSgJHLmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.longer<- corn.wider |>\n",
        "               tidyr::pivot_longer(cols= c(\"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\",                                              \"2018\", \"2019\", \"2020\", \"2021\",  \"2022\"),\n",
        "                          names_to = \"YEAR\", # column need to be wider\n",
        "                          values_to = \"MT\") # data\n",
        "head(corn.longer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqdGV2gro-bH",
        "outputId": "2df6bd03-b482-44d8-bc76-3e11bd1e7397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 10 × 4\n",
            "   STATE_FIPS STATE_NAME YEAR        MT\n",
            "        <dbl> <chr>      <chr>    <dbl>\n",
            " 1          1 Alabama    2012   734353.\n",
            " 2          1 Alabama    2013  1101529.\n",
            " 3          1 Alabama    2014  1151062.\n",
            " 4          1 Alabama    2015   914829.\n",
            " 5          1 Alabama    2016   960171.\n",
            " 6          1 Alabama    2017   996876.\n",
            " 7          1 Alabama    2018   970839.\n",
            " 8          1 Alabama    2019  1138869.\n",
            " 9          1 Alabama    2020  1284292.\n",
            "10          1 Alabama    2021  1407742.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following command combined `select()`, `rename()`, `summarize()` and `pivot_longer()` the data:"
      ],
      "metadata": {
        "id": "d61BniTGH9Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "soil |>\n",
        "  # First select  numerical columns\n",
        "  dplyr::select(SOC, DEM, NDVI, MAP, MAT) |>\n",
        "  # get summary statistics\n",
        "  dplyr::summarise_all(funs(min = min,\n",
        "                      q25 = quantile(., 0.25),\n",
        "                      median = median,\n",
        "                      q75 = quantile(., 0.75),\n",
        "                      max = max,\n",
        "                      mean = mean,\n",
        "                      sd = sd)) |>\n",
        "  # create a nice looking table\n",
        "   tidyr::pivot_longer(everything(), names_sep = \"_\", names_to = c( \"variable\", \".value\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DkTc4T6H9fw",
        "outputId": "c3711db3-9869-44dc-f814-eece21f08551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 5 × 8\n",
            "  variable     min      q25   median      q75      max     mean      sd\n",
            "  <chr>      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>   <dbl>\n",
            "1 SOC        0.408    2.77     4.97     8.71    30.5      6.35    5.05 \n",
            "2 DEM      259.    1175.    1593.    2238.    3618.    1632.    770.   \n",
            "3 NDVI       0.142    0.308    0.417    0.557    0.797    0.437   0.162\n",
            "4 MAP      194.     354.     434.     591.    1128.     501.    207.   \n",
            "5 MAT       -0.591    5.87     9.17    12.4     16.9      8.88    4.10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spread\n",
        "\n",
        "`dplyr::spread()*`is equivalent to `tidyr::pivot_wider()`:"
      ],
      "metadata": {
        "id": "cHdE3nL8IVIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.corn |>\n",
        "  dplyr::select (STATE_FIPS, YEAR, STATE_NAME, MT)  |>\n",
        "  tidyr::spread(YEAR, MT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-yPRw_jIVQc",
        "outputId": "6da1f2da-f983-41e3-c112-51d65134c252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 48 × 13\n",
            "   STATE_FIPS STATE_NAME   `2012`  `2013`  `2014`  `2015`  `2016` `2017`  `2018`\n",
            "        <dbl> <chr>         <dbl>   <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>\n",
            " 1          1 Alabama      7.34e5  1.10e6  1.15e6  9.15e5  9.60e5 9.97e5  9.71e5\n",
            " 2          4 Arizona      1.59e5  2.29e5  1.49e5  1.92e5  2.73e5 1.59e5  1.12e5\n",
            " 3          5 Arkansas     3.14e6  4.11e6  2.52e6  2.05e6  3.24e6 2.77e6  2.97e6\n",
            " 4          6 California   8.23e5  8.73e5  3.98e5  2.39e5  4.70e5 3.39e5  2.86e5\n",
            " 5          8 Colorado     3.41e6  3.26e6  3.75e6  3.43e6  4.07e6 4.72e6  3.93e6\n",
            " 6          9 Connecticut  2.05e4 NA      NA      NA      NA      2.32e4 NA     \n",
            " 7         10 Delaware     6.10e5  7.34e5  8.53e5  8.00e5  7.08e5 8.21e5  6.11e5\n",
            " 8         12 Florida      1.17e5  2.64e5  1.37e5  1.79e5  1.47e5 1.51e5  2.47e5\n",
            " 9         13 Georgia      1.42e6  2.07e6  1.34e6  1.24e6  1.43e6 1.10e6  1.27e6\n",
            "10         16 Idaho        6.69e5  5.29e5  4.06e5  3.68e5  4.78e5 5.93e5  6.76e5\n",
            "# ℹ 38 more rows\n",
            "# ℹ 4 more variables: `2019` <dbl>, `2020` <dbl>, `2021` <dbl>, `2022` <dbl>\n",
            "# ℹ Use `print(n = ...)` to see more rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gather\n",
        "\n",
        "`tidyr::gather()` is equivalent to `tidyr::pivot_longer()`"
      ],
      "metadata": {
        "id": "9SisI7Z5I3na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corr.gathered<-corn.wider  |>\n",
        "        tidyr::gather(key = YEAR, value = MT, -STATE_FIPS, -STATE_NAME)  |>\n",
        "        glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7KiOIVSI5rq",
        "outputId": "13711c5d-c7e7-4cc7-c5aa-36a0c954c9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 451\n",
            "Columns: 4\n",
            "$ STATE_FIPS <dbl> 1, 4, 5, 6, 8, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, …\n",
            "$ STATE_NAME <chr> \"Alabama\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",…\n",
            "$ YEAR       <chr> \"2012\", \"2012\", \"2012\", \"2012\", \"2012\", \"2012\", \"2012\", \"20…\n",
            "$ MT         <dbl> 734352.8, 158504.4, 3142399.9, 823003.5, 3412162.2, 610394.…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Cleaning a messy data\n",
        "\n",
        "This exercise is designed to provide you with a more in-depth understanding of how to clean and prepare data for analysis. Data cleaning involves a set of processes that help to ensure that your data is accurate, consistent, and complete. In this exercise, you will be introduced to various techniques that can be used to address common issues in data such as missing values, data below detection limits, and spatial characters.\n",
        "\n",
        "Missing values can occur when data is not collected or recorded for a particular variable. It is important to address missing values, as they can lead to inaccurate results and bias in your analysis. You will learn how to identify missing values and how to handle them using techniques such as imputation and deletion.\n",
        "Data below detection limits, also known as censored data, are values that are below the limit of detection for a particular measurement. These values can be problematic as they can skew your analysis and lead to inaccurate results. You will learn how to identify censored data and how to handle it using techniques such as substitution and regression.\n",
        "\n",
        "Spatial characters are characters that are used to represent geographical locations in data, such as postcodes or zip codes. However, these characters can sometimes be recorded incorrectly or inconsistently, which can lead to issues in your analysis. You will learn how to identify and clean spatial characters to ensure that your data is accurate and consistent.\n",
        "\n",
        "By the end of this exercise, you will have a solid understanding of how to clean and prepare your data for analysis, which will help you to obtain more accurate and reliable results.\n"
      ],
      "metadata": {
        "id": "rozSSsjJJzwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use National Geochemical Database from United States Geological Survey (USGS) as a part of the USGS Geochemical Landscapes Project (Smith et al., 2011)"
      ],
      "metadata": {
        "id": "gkrXZuCsLiVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.geo<-read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_geochemical_raw.csv\")\n",
        "glimpse(df.geo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAf6rZhZLmtq",
        "outputId": "a4e415cf-ea7c-4f46-a3d8-fbcac0ccb3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 4857 Columns: 56\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr (53): A_LabID, StateID, CollDate, LandCover1, LandCover2, A_Depth, A_Ag,...\n",
            "dbl  (3): SiteID, Latitude, Longitude\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "Rows: 4,857\n",
            "Columns: 56\n",
            "$ A_LabID    <chr> \"C-328943\", \"C-328929\", \"C-328930\", \"C-329034\", \"C-328968\",…\n",
            "$ SiteID     <dbl> 96, 208, 288, 656, 912, 1232, 1312, 1488, 1680, 1824, 2144,…\n",
            "$ StateID    <chr> \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\",…\n",
            "$ Latitude   <dbl> 31.3146, 33.8523, 31.2179, 33.0992, 34.5501, 34.3577, 31.06…\n",
            "$ Longitude  <dbl> -87.1166, -86.9041, -85.8788, -86.9976, -87.6779, -87.3130,…\n",
            "$ CollDate   <chr> \"2/18/2009\", \"2/26/2009\", \"2/18/2009\", \"2/23/2009\", \"2/25/2…\n",
            "$ LandCover1 <chr> \"Planted/Cultivated\", \"Developed\", \"Planted/Cultivated\", \"F…\n",
            "$ LandCover2 <chr> \"Pasture/Hay\", \"Low Intensity Residential\", \"Fallow\", \"Ever…\n",
            "$ A_Depth    <chr> \"0-20\", \"0-20\", \"0-20\", \"0-20\", \"0-5\", \"0-10\", \"0-25\", \"0-3…\n",
            "$ A_Ag       <chr> \"<1\", \"<1\", \"<1\", \"<1\", \"<1\", \"<1\", \"<1\", \"<1\", \"<1\", \"<1\",…\n",
            "$ A_Al       <chr> \"0.87\", \"1.15\", \"1.05\", \"4.17\", \"1.51\", \"2.78\", \"2.14\", \"1.…\n",
            "$ A_As       <chr> \"1.6\", \"1.5\", \"1.2\", \"3.7\", \"2.7\", \"4.3\", \"2.7\", \"3.7\", \"2.…\n",
            "$ A_Ba       <chr> \"49\", \"118\", \"34\", \"316\", \"179\", \"160\", \"50\", \"185\", \"77\", …\n",
            "$ A_Be       <chr> \"0.2\", \"0.4\", \"0.2\", \"1.1\", \"0.6\", \"0.5\", \"0.3\", \"0.5\", \"0.…\n",
            "$ A_Bi       <chr> \"0.08\", \"0.1\", \"0.07\", \"0.16\", \"0.09\", \"0.19\", \"0.16\", \"0.2…\n",
            "$ A_C_Tot    <chr> \"0.71\", \"0.88\", \"0.65\", \"1.14\", \"1.36\", \"1.71\", \"0.89\", \"4.…\n",
            "$ A_C_Inorg  <chr> \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.…\n",
            "$ A_C_Org    <chr> \"0.71\", \"0.88\", \"0.65\", \"1.14\", \"1.36\", \"1.71\", \"0.89\", \"4.…\n",
            "$ A_Ca       <chr> \"0.07\", \"0.02\", \"0.05\", \"0.05\", \"0.03\", \"0.02\", \"0.04\", \"0.…\n",
            "$ A_Cd       <chr> \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"0.…\n",
            "$ A_Ce       <chr> \"25.2\", \"27.8\", \"42.2\", \"41.7\", \"61.7\", \"32.6\", \"48.6\", \"44…\n",
            "$ A_Co       <chr> \"1.2\", \"2.4\", \"1\", \"7\", \"6.1\", \"3.5\", \"1.5\", \"3.9\", \"1.3\", …\n",
            "$ A_Cr       <chr> \"11\", \"14\", \"8\", \"28\", \"17\", \"30\", \"17\", \"22\", \"22\", \"10\", …\n",
            "$ A_Cs       <chr> \"<5\", \"<5\", \"<5\", \"<5\", \"<5\", \"<5\", \"<5\", \"<5\", \"<5\", \"<5\",…\n",
            "$ A_Cu       <chr> \"4.4\", \"6.1\", \"10.9\", \"13.8\", \"5.2\", \"8.4\", \"15.1\", \"10.1\",…\n",
            "$ A_Fe       <chr> \"0.57\", \"0.54\", \"0.38\", \"2.38\", \"1.06\", \"1.66\", \"0.9\", \"1.1…\n",
            "$ A_Ga       <chr> \"1.96\", \"2.24\", \"1.98\", \"9.53\", \"3.29\", \"6.43\", \"4.22\", \"4.…\n",
            "$ A_Hg       <chr> \"0.01\", \"0.02\", \"<0.01\", \"0.03\", \"0.03\", \"0.05\", \"0.02\", \"0…\n",
            "$ A_In       <chr> \"<0.02\", \"<0.02\", \"<0.02\", \"0.03\", \"<0.02\", \"0.02\", \"<0.02\"…\n",
            "$ A_K        <chr> \"0.09\", \"0.25\", \"0.05\", \"0.89\", \"0.44\", \"0.46\", \"0.1\", \"0.3…\n",
            "$ A_La       <chr> \"11.4\", \"13.8\", \"23.4\", \"20.6\", \"21\", \"16.3\", \"22.3\", \"20.9…\n",
            "$ A_Li       <chr> \"5\", \"8\", \"5\", \"21\", \"6\", \"17\", \"9\", \"18\", \"8\", \"4\", \"7\", \"…\n",
            "$ A_Mg       <chr> \"0.03\", \"0.05\", \"0.03\", \"0.16\", \"0.06\", \"0.11\", \"0.04\", \"0.…\n",
            "$ A_Mn       <chr> \"81\", \"191\", \"249\", \"228\", \"321\", \"96\", \"155\", \"598\", \"76\",…\n",
            "$ A_Mo       <chr> \"0.34\", \"0.36\", \"0.41\", \"1.19\", \"0.48\", \"0.66\", \"0.76\", \"0.…\n",
            "$ A_Na       <chr> \"<0.01\", \"0.02\", \"<0.01\", \"0.06\", \"0.06\", \"0.05\", \"<0.01\", …\n",
            "$ A_Nb       <chr> \"5.2\", \"3.5\", \"3.4\", \"8.4\", \"0.6\", \"9.1\", \"7.1\", \"6.1\", \"2.…\n",
            "$ A_Ni       <chr> \"3.2\", \"4.6\", \"4.2\", \"11.5\", \"6.9\", \"8.4\", \"7.7\", \"7\", \"3.8…\n",
            "$ A_P        <chr> \"260\", \"170\", \"510\", \"200\", \"200\", \"190\", \"680\", \"440\", \"10…\n",
            "$ A_Pb       <chr> \"6.8\", \"11.6\", \"7\", \"14\", \"14.5\", \"15.4\", \"10.5\", \"26.6\", \"…\n",
            "$ A_Rb       <chr> \"8.4\", \"20\", \"5.7\", \"57.8\", \"24.6\", \"31.8\", \"9\", \"24.7\", \"1…\n",
            "$ A_S        <chr> \"<0.01\", \"<0.01\", \"<0.01\", \"0.01\", \"0.01\", \"0.01\", \"<0.01\",…\n",
            "$ A_Sb       <chr> \"0.19\", \"0.23\", \"0.19\", \"0.62\", \"0.1\", \"0.46\", \"0.3\", \"0.4\"…\n",
            "$ A_Sc       <chr> \"1.6\", \"1.6\", \"1.4\", \"7.5\", \"2.2\", \"4.1\", \"3.1\", \"2.5\", \"3.…\n",
            "$ A_Se       <chr> \"<0.2\", \"<0.2\", \"<0.2\", \"0.5\", \"<0.2\", \"0.4\", \"0.2\", \"0.4\",…\n",
            "$ A_Sn       <chr> \"0.5\", \"0.5\", \"0.6\", \"1.3\", \"0.4\", \"1\", \"1.1\", \"1.3\", \"1\", …\n",
            "$ A_Sr       <chr> \"6.2\", \"15.2\", \"3.9\", \"30.4\", \"21.9\", \"27.2\", \"6.7\", \"27.9\"…\n",
            "$ A_Te       <chr> \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0…\n",
            "$ A_Th       <chr> \"4.4\", \"3.2\", \"3\", \"8.2\", \"5\", \"7.1\", \"7.2\", \"5.9\", \"9.2\", …\n",
            "$ A_Ti       <chr> \"0.24\", \"0.13\", \"0.13\", \"0.31\", \"0.05\", \"0.28\", \"0.3\", \"0.1…\n",
            "$ A_Tl       <chr> \"<0.1\", \"0.2\", \"<0.1\", \"0.5\", \"0.3\", \"0.4\", \"0.1\", \"0.3\", \"…\n",
            "$ A_U        <chr> \"1.4\", \"1.1\", \"1\", \"2.4\", \"1.4\", \"2.2\", \"2\", \"1.9\", \"1.9\", …\n",
            "$ A_V        <chr> \"14\", \"16\", \"12\", \"56\", \"21\", \"37\", \"27\", \"30\", \"26\", \"22\",…\n",
            "$ A_W        <chr> \"0.3\", \"0.3\", \"0.4\", \"0.8\", \"<0.1\", \"0.7\", \"0.6\", \"0.4\", \"<…\n",
            "$ A_Y        <chr> \"3.8\", \"4.9\", \"16.3\", \"8.8\", \"8.4\", \"6.7\", \"9.1\", \"9.4\", \"5…\n",
            "$ A_Zn       <chr> \"15\", \"17\", \"19\", \"32\", \"32\", \"28\", \"26\", \"48\", \"20\", \"34\",…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first create a dataframe with limited number of variables using `select()` functions and rename them:\n"
      ],
      "metadata": {
        "id": "aQ2CUgLqJ-8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo <- df.geo  |>\n",
        "      select(A_LabID, StateID,  LandCover1, A_Depth, A_C_Tot, A_C_Inorg, A_C_Org, A_As, A_Cd,  A_Pb, A_Cr) |>\n",
        "      rename(\"LAB_ID\"=A_LabID,\n",
        "             \"LandCover\" =LandCover1,\n",
        "             \"Soil_depth\" = A_Depth,\n",
        "             \"Total_Carbon\" = A_C_Tot,\n",
        "             \"Inorg_Carbon\" = A_C_Inorg,\n",
        "             \"Organic_Carbon\"= A_C_Org,\n",
        "             \"Arsenic\" = A_As,\n",
        "             \"Cadmium\" = A_Cd,\n",
        "             \"Lead\" = A_Pb,\n",
        "             \"Chromium\" = A_Cr) |>\n",
        "     glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4pm7bMRMDgb",
        "outputId": "ffe789d6-7df1-43fb-f24d-f1fb69940317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 4,857\n",
            "Columns: 11\n",
            "$ LAB_ID         <chr> \"C-328943\", \"C-328929\", \"C-328930\", \"C-329034\", \"C-3289…\n",
            "$ StateID        <chr> \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"…\n",
            "$ LandCover      <chr> \"Planted/Cultivated\", \"Developed\", \"Planted/Cultivated\"…\n",
            "$ Soil_depth     <chr> \"0-20\", \"0-20\", \"0-20\", \"0-20\", \"0-5\", \"0-10\", \"0-25\", …\n",
            "$ Total_Carbon   <chr> \"0.71\", \"0.88\", \"0.65\", \"1.14\", \"1.36\", \"1.71\", \"0.89\",…\n",
            "$ Inorg_Carbon   <chr> \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\", \"N.D.\",…\n",
            "$ Organic_Carbon <chr> \"0.71\", \"0.88\", \"0.65\", \"1.14\", \"1.36\", \"1.71\", \"0.89\",…\n",
            "$ Arsenic        <chr> \"1.6\", \"1.5\", \"1.2\", \"3.7\", \"2.7\", \"4.3\", \"2.7\", \"3.7\",…\n",
            "$ Cadmium        <chr> \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\", \"<0.1\",…\n",
            "$ Lead           <chr> \"6.8\", \"11.6\", \"7\", \"14\", \"14.5\", \"15.4\", \"10.5\", \"26.6…\n",
            "$ Chromium       <chr> \"11\", \"14\", \"8\", \"28\", \"17\", \"30\", \"17\", \"22\", \"22\", \"1…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we `filter()` the data where records have N.S. values INS:"
      ],
      "metadata": {
        "id": "n2-iriRRMIme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo<- mf.geo |>\n",
        "        filter(Soil_depth != \"N.S.\" & Total_Carbon !=\"INS\")"
      ],
      "metadata": {
        "id": "RAtj_gk7MJST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we will convert all N.D. values to empty string:"
      ],
      "metadata": {
        "id": "077F9JYYMPXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo[mf.geo==\"N.D.\"]<- \"\""
      ],
      "metadata": {
        "id": "ZG1WBRsOMkhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here detection limits of As, Cd, Pb and Cr are 0.6, 0.1, 0.5, and 1 mg/kg, respectively. We will replace the values below detection limits by half of detection limits of these heavy-metals. Before that we have to remove **\"\\<\"** and convert the all <chr> to <double>."
      ],
      "metadata": {
        "id": "DVcVAd0rMtou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo <- mf.geo  |>\n",
        "      mutate_at(c(\"Arsenic\", \"Cadmium\", \"Lead\", \"Chromium\"), str_replace, \"<\", \"\")  |>\n",
        "      mutate_at(c(5:11), as.numeric)  |>\n",
        "     glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0lA2S_JNDkf",
        "outputId": "5d872181-a368-4e26-df3b-08c8f898f8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 4,809\n",
            "Columns: 11\n",
            "$ LAB_ID         <chr> \"C-328943\", \"C-328929\", \"C-328930\", \"C-329034\", \"C-3289…\n",
            "$ StateID        <chr> \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"…\n",
            "$ LandCover      <chr> \"Planted/Cultivated\", \"Developed\", \"Planted/Cultivated\"…\n",
            "$ Soil_depth     <chr> \"0-20\", \"0-20\", \"0-20\", \"0-20\", \"0-5\", \"0-10\", \"0-25\", …\n",
            "$ Total_Carbon   <dbl> 0.71, 0.88, 0.65, 1.14, 1.36, 1.71, 0.89, 4.59, 2.32, 0…\n",
            "$ Inorg_Carbon   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n",
            "$ Organic_Carbon <dbl> 0.71, 0.88, 0.65, 1.14, 1.36, 1.71, 0.89, 4.59, 2.32, 0…\n",
            "$ Arsenic        <dbl> 1.6, 1.5, 1.2, 3.7, 2.7, 4.3, 2.7, 3.7, 2.9, 3.0, 2.3, …\n",
            "$ Cadmium        <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, …\n",
            "$ Lead           <dbl> 6.8, 11.6, 7.0, 14.0, 14.5, 15.4, 10.5, 26.6, 13.2, 12.…\n",
            "$ Chromium       <dbl> 11, 14, 8, 28, 17, 30, 17, 22, 22, 10, 17, 10, 31, 11, …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now replace values below detection limits:"
      ],
      "metadata": {
        "id": "eDOaK7yjNTco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo[\"Arsenic\"][mf.geo[\"Arsenic\"] == 0.6] <- 0.3\n",
        "mf.geo[\"Cadmium\"][mf.geo[\"Cadmium\"] == 0.1] <- 0.05\n",
        "mf.geo[\"Lead\"][mf.geo[\"Lead\"] == 0.5] <- 0.25\n",
        "mf.geo[\"Chromium\"][mf.geo[\"Chromium\"] == 1] <- 0.5"
      ],
      "metadata": {
        "id": "ie-MQit6NUHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now will check the missing values of the data:"
      ],
      "metadata": {
        "id": "nQHnClyRNgCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# counting unique, missing, and median values\n",
        "Arsenic<- mf.geo %>% summarise(N = length(Arsenic),\n",
        "                 na = sum(is.na(Arsenic)),\n",
        "                 Min = min(Arsenic, na.rm = TRUE),\n",
        "                 Max =max(Arsenic, na.rm = TRUE))\n",
        "\n",
        "Cadmium<- mf.geo %>% summarise(N = length(Cadmium),\n",
        "                 na = sum(is.na(Cadmium)),\n",
        "                 Min = min(Cadmium, na.rm = TRUE),\n",
        "                 Max =max(Cadmium, na.rm = TRUE))\n",
        "\n",
        "Lead<- mf.geo %>% summarise(N = length(Lead),\n",
        "                 na = sum(is.na(Lead)),\n",
        "                 Min = min(Lead, na.rm = TRUE),\n",
        "                 Max =max(Lead, na.rm = TRUE))\n",
        "\n",
        "Chromium<- mf.geo %>% summarise(N = length(Chromium),\n",
        "                 na = sum(is.na(Chromium)),\n",
        "                 Min = min(Chromium, na.rm = TRUE),\n",
        "                 Max =max(Chromium, na.rm = TRUE),\n",
        "                 )\n",
        "#bind the data\n",
        "geo.sum<- bind_rows(Arsenic, Cadmium, Lead, Chromium)\n",
        "\n",
        "#add.row.names\n",
        "row.names(geo.sum) <- c(\"Arsenic\", \"Cadmium\", \"Lead\", \"Chromium\")\n",
        "head(geo.sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDvtMDUPNgKM",
        "outputId": "e6cf1853-dd5a-4a08-c6ab-d2e08c0e2a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 4 × 4\n",
            "      N    na   Min    Max\n",
            "  <int> <int> <dbl>  <dbl>\n",
            "1  4809     0  0.3  1110  \n",
            "2  4809     0  0.05   46.6\n",
            "3  4809     0  0.25 2200  \n",
            "4  4809     0  0.5  3850  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the common method of replacing missing values is `na.omit`. The function `na.omit()` returns the object with listwise deletion of missing values and function create new dataset without missing data."
      ],
      "metadata": {
        "id": "0FGRiVRTNuti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "newdata <- na.omit(mf.geo)\n",
        "glimpse(newdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzSE2wtNu01",
        "outputId": "6ebdc8de-a9f2-4bb8-9796-00f0cfe53aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1,167\n",
            "Columns: 11\n",
            "$ LAB_ID         <chr> \"C-329044\", \"C-329030\", \"C-329081\", \"C-329079\", \"C-3289…\n",
            "$ StateID        <chr> \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\", \"AZ\", \"AZ\", \"…\n",
            "$ LandCover      <chr> \"Planted/Cultivated\", \"Developed\", \"Planted/Cultivated\"…\n",
            "$ Soil_depth     <chr> \"0-20\", \"0-20\", \"0-15\", \"0-7\", \"0-20\", \"0-10\", \"0-5\", \"…\n",
            "$ Total_Carbon   <dbl> 2.90, 4.78, 0.75, 1.69, 1.00, 1.00, 1.88, 0.31, 2.13, 0…\n",
            "$ Inorg_Carbon   <dbl> 1.8, 3.7, 0.1, 0.1, 0.2, 0.1, 0.1, 0.2, 0.9, 0.4, 0.1, …\n",
            "$ Organic_Carbon <dbl> 1.1, 1.1, 0.7, 1.6, 0.8, 0.9, 1.8, 0.1, 1.2, 0.3, 0.8, …\n",
            "$ Arsenic        <dbl> 5.9, 7.9, 5.6, 7.2, 2.9, 4.8, 1.9, 5.3, 4.5, 5.0, 4.0, …\n",
            "$ Cadmium        <dbl> 0.20, 0.20, 0.05, 0.20, 0.05, 0.05, 0.05, 0.20, 0.20, 0…\n",
            "$ Lead           <dbl> 20.9, 19.1, 12.9, 21.1, 14.1, 11.9, 8.7, 26.8, 14.7, 24…\n",
            "$ Chromium       <dbl> 73, 68, 37, 42, 36, 31, 16, 36, 35, 28, 30, 25, 62, 21,…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function delete all records with missing values. Now newdata have only 1,167 records, since Inorg_Carbon variable has 3,690 missing values which all are omitted.\n",
        "\n",
        "We can impute missing values in several ways. The easiest way to impute missing values is by replacing the mean values of the variable. The following code replace missing of Arsenic, Cadmium, Lead and Chromium with their mean values."
      ],
      "metadata": {
        "id": "hCaoEGFbN3K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo.new<-mf.geo  |>\n",
        "  mutate_at(vars(Arsenic, Cadmium, Lead, Chromium),~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x)) |>\n",
        "  glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf0lWylDN4G6",
        "outputId": "1c32c4df-ea4f-4855-9caa-f1aa11209f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 4,809\n",
            "Columns: 11\n",
            "$ LAB_ID         <chr> \"C-328943\", \"C-328929\", \"C-328930\", \"C-329034\", \"C-3289…\n",
            "$ StateID        <chr> \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"…\n",
            "$ LandCover      <chr> \"Planted/Cultivated\", \"Developed\", \"Planted/Cultivated\"…\n",
            "$ Soil_depth     <chr> \"0-20\", \"0-20\", \"0-20\", \"0-20\", \"0-5\", \"0-10\", \"0-25\", …\n",
            "$ Total_Carbon   <dbl> 0.71, 0.88, 0.65, 1.14, 1.36, 1.71, 0.89, 4.59, 2.32, 0…\n",
            "$ Inorg_Carbon   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n",
            "$ Organic_Carbon <dbl> 0.71, 0.88, 0.65, 1.14, 1.36, 1.71, 0.89, 4.59, 2.32, 0…\n",
            "$ Arsenic        <dbl> 1.6, 1.5, 1.2, 3.7, 2.7, 4.3, 2.7, 3.7, 2.9, 3.0, 2.3, …\n",
            "$ Cadmium        <dbl> 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.20, 0.05, 0…\n",
            "$ Lead           <dbl> 6.8, 11.6, 7.0, 14.0, 14.5, 15.4, 10.5, 26.6, 13.2, 12.…\n",
            "$ Chromium       <dbl> 11, 14, 8, 28, 17, 30, 17, 22, 22, 10, 17, 10, 31, 11, …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mf.geo.new  |>\n",
        "  summarise(sum(is.na(Chromium)))"
      ],
      "metadata": {
        "id": "zlTEFy6DOR_v",
        "outputId": "1b94f5d2-b352-4343-a24e-cd9d5973f7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# A tibble: 1 × 1\n",
            "  `sum(is.na(Chromium))`\n",
            "                   <int>\n",
            "1                      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ovc25MJTsD8"
      },
      "source": [
        "## Further Reading\n",
        "\n",
        "1.  [R for Data Science](https://r4ds.had.co.nz/)\n",
        "\n",
        "2.  [Data Wrangling with R](https://cengel.github.io/R-data-wrangling/)\n",
        "\n",
        "3.  [Book: Data Wrangling with R](https://link.springer.com/book/10.1007/978-3-319-45599-0)\n",
        "\n",
        "4.  [PDF Data wrangling with R and RStudio](https://github.com/rstudio/webinars/blob/master/05-Data-Wrangling-with-R-and-RStudio/wrangling-webinar.pdf)\n",
        "\n",
        "5.  [Youtube Data Wrangling with R and the Tidyverse - Workshop](https://www.youtube.com/watch?v=CnY5Y5ANnjE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCdjPBDaRiN1fy9PGh8i04",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}